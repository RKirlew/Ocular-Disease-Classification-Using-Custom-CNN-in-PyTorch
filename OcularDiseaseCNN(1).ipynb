{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!file archive\\(6\\).zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-5dFYPTOJeJ",
        "outputId": "44312859-d7e5-432a-c9db-f9f24a82df11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive(6).zip: Zip archive data, at least v4.5 to extract, compression method=deflate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53xjzepOkX7",
        "outputId": "127c0834-71fe-4c34-f2a5-43c837546816"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-3.1.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading patool-3.1.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m92.2/98.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive('archive(6).zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "oKuW6QYaOOgk",
        "outputId": "54507295-19e3-49c2-8d91-6aad4e49a5d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting archive(6).zip ...\n",
            "INFO:patool:Extracting archive(6).zip ...\n",
            "INFO patool: running /usr/bin/7z x -aou -o./Unpack_9i1uk4_2 -- archive(6).zip\n",
            "INFO:patool:running /usr/bin/7z x -aou -o./Unpack_9i1uk4_2 -- archive(6).zip\n",
            "ERROR patool: extraction error, could not remove temporary extraction directory ./Unpack_9i1uk4_2: [Errno 39] Directory not empty: './Unpack_9i1uk4_2'\n",
            "ERROR:patool:extraction error, could not remove temporary extraction directory ./Unpack_9i1uk4_2: [Errno 39] Directory not empty: './Unpack_9i1uk4_2'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PatoolError",
          "evalue": "Command `['/usr/bin/7z', 'x', '-aou', '-o./Unpack_9i1uk4_2', '--', 'archive(6).zip']' returned non-zero exit status 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPatoolError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-519606674a9f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatoolib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpatoolib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'archive(6).zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(archive, verbosity, outdir, program, interactive, password)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {archive} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m     return _extract_archive(\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36m_extract_archive\u001b[0;34m(archive, verbosity, interactive, outdir, program, format, compression, password)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0;31m# already handled the command (e.g. when it's a builtin Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mrun_archive_cmdlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_cleanup_outdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup_outdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/patoolib/__init__.py\u001b[0m in \u001b[0;36mrun_archive_cmdlist\u001b[0;34m(archive_cmdlist, verbosity)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_cmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_checked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrunkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/patoolib/util.py\u001b[0m in \u001b[0;36mrun_checked\u001b[0;34m(cmd, ret_ok, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Command `{cmd}' returned non-zero exit status {retcode}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPatoolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPatoolError\u001b[0m: Command `['/usr/bin/7z', 'x', '-aou', '-o./Unpack_9i1uk4_2', '--', 'archive(6).zip']' returned non-zero exit status 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 256)  #Adjust based on input size\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64 * 56 * 56)  #Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "huc3VCcCPGjL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=\"/content/Fundus/1000images/\", transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Hlp9OiAZPk8C"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lvZbIrmeQgk",
        "outputId": "272b06a9-21b9-4956-d548-b986d95c193c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.0.Normal', '0.1.Tessellated fundus', '0.2.Large optic cup', '0.3.DR1', '1.0.DR2', '1.1.DR3', '10.0.Possible glaucoma', '10.1.Optic atrophy', '11.Severe hypertensive retinopathy', '12.Disc swelling and elevation', '13.Dragged Disc', '14.Congenital disc abnormality', '15.0.Retinitis pigmentosa', '15.1.Bietti crystalline dystrophy', '16.Peripheral retinal degeneration and break', '17.Myelinated nerve fiber', '18.Vitreous particles', '19.Fundus neoplasm', '2.0.BRVO', '2.1.CRVO', '20.Massive hard exudates', '21.Yellow-white spots-flecks', '22.Cotton-wool spots', '23.Vessel tortuosity', '24.Chorioretinal atrophy-coloboma', '25.Preretinal hemorrhage', '26.Fibrosis', '27.Laser Spots', '28.Silicon oil in eye', '29.0.Blur fundus without PDR', '29.1.Blur fundus with suspected PDR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = CustomCNN(num_classes=len(dataset.classes))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "fMpEpDlaP5as"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDtT9z9zP6jy",
        "outputId": "624e1aad-a155-48d6-f702-e02987d77b0a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 5.6766, Training Accuracy: 11.15%\n",
            "Validation Loss: 3.1603, Validation Accuracy: 17.36%\n",
            "Epoch 2/10, Training Loss: 2.8745, Training Accuracy: 24.22%\n",
            "Validation Loss: 2.8322, Validation Accuracy: 28.47%\n",
            "Epoch 3/10, Training Loss: 2.4098, Training Accuracy: 35.54%\n",
            "Validation Loss: 2.6275, Validation Accuracy: 34.72%\n",
            "Epoch 4/10, Training Loss: 1.8559, Training Accuracy: 44.43%\n",
            "Validation Loss: 2.6780, Validation Accuracy: 34.72%\n",
            "Epoch 5/10, Training Loss: 1.4558, Training Accuracy: 58.01%\n",
            "Validation Loss: 3.2920, Validation Accuracy: 31.94%\n",
            "Epoch 6/10, Training Loss: 1.1268, Training Accuracy: 66.72%\n",
            "Validation Loss: 3.2452, Validation Accuracy: 34.03%\n",
            "Epoch 7/10, Training Loss: 1.0223, Training Accuracy: 71.60%\n",
            "Validation Loss: 3.6663, Validation Accuracy: 33.33%\n",
            "Epoch 8/10, Training Loss: 0.8461, Training Accuracy: 74.91%\n",
            "Validation Loss: 4.0035, Validation Accuracy: 28.47%\n",
            "Epoch 9/10, Training Loss: 0.6610, Training Accuracy: 80.49%\n",
            "Validation Loss: 4.0624, Validation Accuracy: 31.94%\n",
            "Epoch 10/10, Training Loss: 0.4645, Training Accuracy: 85.71%\n",
            "Validation Loss: 4.9547, Validation Accuracy: 33.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"ocular_cnn.pth\")"
      ],
      "metadata": {
        "id": "ZjOqnbTudTOV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomCNN(num_classes=len(dataset.classes))\n",
        "model.load_state_dict(torch.load(\"ocular_cnn.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TuGunMsdgQ8",
        "outputId": "158bf77c-db4a-4c84-b51a-b319ce2b5a7e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-c3564d577793>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"ocular_cnn.pth\"))  # Load the saved model state\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomCNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=200704, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=31, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "image_path = \"retino.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image = transform(image).unsqueeze(0)\n",
        "\n",
        "#Predict\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "    predicted_label = dataset.classes[predicted_class.item()]\n",
        "    print(f\"Predicted Disease: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mnShfB1dhbV",
        "outputId": "e983a109-9a03-472c-8b9e-0f7b8a850787"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Disease: 11.Severe hypertensive retinopathy\n"
          ]
        }
      ]
    }
  ]
}